# Set the start and end dates to process (mandatory), for the initial release needs to be minimum of two days
#
START_DATE=
#START_DATE="2025/8/14"
#
END_DATE=
#END_DATE="2025/8/20"
#
# This is the top level directory/folder where all scripts, and by default, where the static & dynamic settings file
#  and the log file are located (mandatory)
BASEDIR=
#BASEDIR=/opt/scripts
#
# Set the path so everything knows where to be found (please do not adjust unless GNU Parallel is moved)
PATH=$PATH:$BASEDIR/parallel/bin/
#
# Most importantly, set where the output files will go.  Any directory/folder, including the TLD will be created as necessary
#  Can't stress enough how storage intensive this conversion of data will be.  One test turned 3.6GB of Ariel DB files
#   into 27GB of uncompressed JSON output files.   Make _SURE_ you have enough storage space to handle things.  (mandatory)
CONVERTED_DATA_DESTINATION=
CONVERTED_DATA_DESTINATION=/store/processing_out
#
# This temporary location is needed for the most awesome script 'GNU Parallel' to function.  Nothing permanently stored here
TMPDIR=
#TMPDIR=/store/processing_out/tmpdir
#
# Here is where the log file is going to be written (default).   Highly advisable to watch (tail -f) this file (mandatory)
LOGFILE=${BASEDIR}/logfile_ariel_dump.log
#LOGFILE=${BASEDIR}/logfile_ariel_dump.log
#

#
# Everything below this line will be coded in the future
# Zero out log file at start of job.   Uncomment to preserve log file.
# - needs to be coded, future enhancement
#ZERO_LOGFILE=yes
#
# Uncomment the below to compress the output JSON files (very recommended)
# - default is to be compressed.   
# -  needs to be coded, future enhancement
#COMPRESS_OUTPUT=yes
#
#
##  Collation options
#
# Uncomment one of these to control collation.
#  output one JSON file per time frame per log-source type.
# - needs to be coded, future enhancement
#LOG_SOURCE_TYPE_COLLATION=per-day
#LOG_SOURCE_TYPE_COLLATION=per-hour
#
#
